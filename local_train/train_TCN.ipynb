{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lightning.fabric import Fabric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../models')\n",
    "\n",
    "import TCN\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "# 1 + 2 * (kernel_size - 1) * (2 ^ num_layers - 1) should > 10000\n",
    "kernel_size = 21\n",
    "num_layers = 3\n",
    "out_channels = [32] * num_layers\n",
    "dilation_base = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../hms-train/train.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=8056)\n",
    "\n",
    "train_dataset_high_votes = utils.EEGCleanDataset(train_df, 4)\n",
    "train_dataset_low_votes = utils.EEGCleanDataset(train_df, (1, 4))\n",
    "val_dataset = utils.EEGCleanDataset(val_df)\n",
    "\n",
    "train_loader_high_votes = DataLoader(train_dataset_high_votes, batch_size=64, shuffle=True)\n",
    "train_loader_low_votes = DataLoader(train_dataset_low_votes, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = TCN.TCN(input_size, out_channels, kernel_size, dilation_base)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# fabric module\n",
    "fabric = Fabric(accelerator='cuda', precision='16-mixed')\n",
    "model, optimizer = fabric.setup(model, optimizer)\n",
    "train_loader_high_votes = fabric.setup_dataloaders(train_loader_high_votes)\n",
    "train_loader_low_votes = fabric.setup_dataloaders(train_loader_low_votes)\n",
    "val_loader = fabric.setup_dataloaders(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "# lr = 0.001    if epoch < 21\n",
    "# lr = 0.0001    if 21 <= epoch < 42\n",
    "# lr = 0.00001   if 42 <= epoch < 63\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=21, gamma=0.1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch_high_votes, batch_low_votes in zip(tqdm(train_loader_high_votes, \n",
    "                                                      desc=f'Train {epoch + 1}/{epochs}'\n",
    "                                                      ), \n",
    "                                                 train_loader_low_votes):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        eeg_high_votes, _, class_prob_high_votes = batch_high_votes\n",
    "        outputs1 = model.forward(eeg_high_votes)\n",
    "        kl_loss1 = kl_loss_fn(outputs1, class_prob_high_votes)\n",
    "        \n",
    "        eeg_low_votes, _, class_prob_low_votes = batch_low_votes\n",
    "        outputs2 = model.forward(eeg_low_votes)\n",
    "        kl_loss2 = kl_loss_fn(outputs2, class_prob_low_votes)\n",
    "        \n",
    "        # if torch.sum(torch.isnan(outputs)) > 0:\n",
    "        #     print(outputs)\n",
    "        #     break\n",
    "        kl_loss = kl_loss1 + kl_loss2 * 0.2\n",
    "        fabric.backward(kl_loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += kl_loss.item() * (eeg_high_votes.size(0))\n",
    "\n",
    "    running_val_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    for val_eeg, val_label, val_class_prob in tqdm(val_loader, desc=f'Validation {epoch + 1}/{epochs}'):\n",
    "        val_outputs = model.forward(val_eeg)\n",
    "        pred = torch.argmax(val_outputs, dim=1)\n",
    "        kl_val_loss = kl_loss_fn(val_outputs, val_class_prob)\n",
    "        \n",
    "        running_val_loss += kl_val_loss.item() * val_eeg.size(0)\n",
    "    \n",
    "    # scheduler.step()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1} Train KL loss: ', running_loss / len(train_dataset_high_votes))\n",
    "    print(f'Epoch {epoch + 1} Val KL loss: ', running_val_loss / len(val_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
